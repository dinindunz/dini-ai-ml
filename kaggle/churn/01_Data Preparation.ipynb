{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit\n",
    "import shutil\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has been added for scenarios where you might\n",
    "# wish to alter some of the churn label prediction\n",
    "# logic but do not wish to rerun the whole notebook\n",
    "skip_reload = False\n",
    "\n",
    "# please use a personalized database name here if you wish to avoid interfering with other users who might be running this accelerator in the same workspace\n",
    "database_name = 'kkbox_churn'\n",
    "data_dir = f\"{os.getenv('HOME')}/databricks/kkbox_churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()  # Properly stop Spark\n",
    "del spark     # Delete the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ChurnCluster\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.2.1\") \\\n",
    "    .config(\"spark.executor.memory\", \"56g\") \\\n",
    "    .config(\"spark.driver.memory\", \"56g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "os.environ[\"SPARK_APP_NAME\"] = spark.conf.get(\"spark.app.name\")\n",
    "os.environ[\"SPARK_MASTER\"] = spark.conf.get(\"spark.master\")\n",
    "\n",
    "print(\"Spark Version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_reload:\n",
    "  # create database to house SQL tables\n",
    "  _ = spark.sql(f'CREATE DATABASE IF NOT EXISTS {database_name}')\n",
    "  _ = spark.sql(f'USE {database_name}')\n",
    "else:\n",
    "  # delete the old database if needed\n",
    "  _ = spark.sql(f'DROP DATABASE IF EXISTS {database_name} CASCADE')\n",
    "  _ = spark.sql(f'CREATE DATABASE {database_name}')\n",
    "  _ = spark.sql(f'USE {database_name}')\n",
    "\n",
    "  # drop any old delta lake files that might have been created\n",
    "  folder_path = f'{data_dir}/silver/members'\n",
    "  if os.path.exists(folder_path):\n",
    "      shutil.rmtree(folder_path)\n",
    "    \n",
    "  # members dataset schema\n",
    "  member_schema = StructType([\n",
    "    StructField('msno', StringType()),\n",
    "    StructField('city', IntegerType()),\n",
    "    StructField('bd', IntegerType()),\n",
    "    StructField('gender', StringType()),\n",
    "    StructField('registered_via', IntegerType()),\n",
    "    StructField('registration_init_time', DateType())\n",
    "    ])\n",
    "\n",
    "  # read data from csv\n",
    "  members = (\n",
    "    spark\n",
    "      .read\n",
    "      .csv(\n",
    "        f'{data_dir}/members/members_v3.csv',\n",
    "        schema=member_schema,\n",
    "        header=True,\n",
    "        dateFormat='yyyyMMdd'\n",
    "        )\n",
    "      )\n",
    "\n",
    "  # persist in delta lake format\n",
    "  (\n",
    "    members\n",
    "      .write\n",
    "      .format('delta')\n",
    "      .mode('overwrite')\n",
    "      .save(f'{data_dir}/silver/members')\n",
    "    )\n",
    "\n",
    "    # create table object to make delta lake queryable\n",
    "  _ = spark.sql('''\n",
    "      CREATE TABLE members \n",
    "      USING DELTA \n",
    "      LOCATION '/home/dinindu/databricks/kkbox_churn/silver/members'\n",
    "      ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(members.show())\n",
    "result = spark.sql(\"SELECT * FROM kkbox_churn.members LIMIT 10\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_reload:\n",
    "\n",
    "  # drop any old delta lake files that might have been created\n",
    "  folder_path = f'{data_dir}/silver/transactions'\n",
    "  if os.path.exists(folder_path):\n",
    "      shutil.rmtree(folder_path)\n",
    "\n",
    "  # transaction dataset schema\n",
    "  transaction_schema = StructType([\n",
    "    StructField('msno', StringType()),\n",
    "    StructField('payment_method_id', IntegerType()),\n",
    "    StructField('payment_plan_days', IntegerType()),\n",
    "    StructField('plan_list_price', IntegerType()),\n",
    "    StructField('actual_amount_paid', IntegerType()),\n",
    "    StructField('is_auto_renew', IntegerType()),\n",
    "    StructField('transaction_date', DateType()),\n",
    "    StructField('membership_expire_date', DateType()),\n",
    "    StructField('is_cancel', IntegerType())  \n",
    "    ])\n",
    "\n",
    "  # read data from csv\n",
    "  transactions = (\n",
    "    spark\n",
    "      .read\n",
    "      .csv(\n",
    "        f'{data_dir}/transactions/transactions.csv',\n",
    "        schema=transaction_schema,\n",
    "        header=True,\n",
    "        dateFormat='yyyyMMdd'\n",
    "        )\n",
    "      )\n",
    "\n",
    "  # persist in delta lake format\n",
    "  ( transactions\n",
    "      .write\n",
    "      .format('delta')\n",
    "      .partitionBy('transaction_date')\n",
    "      .mode('overwrite')\n",
    "      .save(f'{data_dir}/silver/transactions')\n",
    "    )\n",
    "\n",
    "    # create table object to make delta lake queryable\n",
    "  _ = spark.sql('''\n",
    "      CREATE TABLE transactions\n",
    "      USING DELTA \n",
    "      LOCATION '/home/dinindu/databricks/kkbox_churn/silver/transactions'\n",
    "      ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(transactions.show())\n",
    "result = spark.sql(\"SELECT * FROM kkbox_churn.transactions LIMIT 10\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_reload:\n",
    "  # drop any old delta lake files that might have been created\n",
    "  folder_path = f'{data_dir}/silver/user_logs'\n",
    "  if os.path.exists(folder_path):\n",
    "      shutil.rmtree(folder_path)\n",
    "\n",
    "  # transaction dataset schema\n",
    "  user_logs_schema = StructType([ \n",
    "    StructField('msno', StringType()),\n",
    "    StructField('date', DateType()),\n",
    "    StructField('num_25', IntegerType()),\n",
    "    StructField('num_50', IntegerType()),\n",
    "    StructField('num_75', IntegerType()),\n",
    "    StructField('num_985', IntegerType()),\n",
    "    StructField('num_100', IntegerType()),\n",
    "    StructField('num_uniq', IntegerType()),\n",
    "    StructField('total_secs', FloatType())  \n",
    "    ])\n",
    "\n",
    "  # read data from csv\n",
    "  user_logs = (\n",
    "    spark\n",
    "      .read\n",
    "      .csv(\n",
    "        f'{data_dir}/user_logs/user_logs.csv',\n",
    "        schema=user_logs_schema,\n",
    "        header=True,\n",
    "        dateFormat='yyyyMMdd'\n",
    "        )\n",
    "      )\n",
    "\n",
    "  # persist in delta lake format\n",
    "  ( user_logs\n",
    "      .write\n",
    "      .format('delta')\n",
    "      .partitionBy('date')\n",
    "      .mode('overwrite')\n",
    "      .save(f'{data_dir}/silver/user_logs')\n",
    "    )\n",
    "\n",
    "  # create table object to make delta lake queryable\n",
    "  _ = spark.sql('''\n",
    "    CREATE TABLE IF NOT EXISTS user_logs\n",
    "    USING DELTA \n",
    "    LOCATION '/home/dinindu/databricks/kkbox_churn/silver/user_logs'\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete training labels if exists before create\n",
    "_ = spark.sql('DROP TABLE IF EXISTS train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -e\n",
    "\n",
    "# Create a spark cluster. But not required.\n",
    "docker network create spark-net\n",
    "\n",
    "docker run -d --rm --network spark-net --name spark-master \\\n",
    "    -p 8080:8080 -p 7077:7077 -p 4040:4040 \\\n",
    "    bitnami/spark spark-class org.apache.spark.deploy.master.Master\n",
    "\n",
    "docker run -d --rm --network spark-net --name spark-worker \\\n",
    "    --env SPARK_MODE=worker \\\n",
    "    --env SPARK_MASTER_URL=spark://spark-master:7077 \\\n",
    "    bitnami/spark spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training labels\n",
    "%%sh -e\n",
    "\n",
    "kkbox_churn_dir=\"/home/dinindu/databricks/kkbox_churn\"\n",
    "sudo chmod 777 $kkbox_churn_dir\n",
    "sudo rm -rf $kkbox_churn_dir/silver/train\n",
    "\n",
    "docker run --rm --network host  \\\n",
    "    -v \"$kkbox_churn_dir:/opt/spark/work/kkbox_churn\" \\\n",
    "    -v \"$PWD:/opt/bitnami/spark/work\" \\\n",
    "    bitnami/spark:3.4.1 spark-shell --master local[*] \\\n",
    "    --executor-memory 48G \\\n",
    "    --driver-memory 16G \\\n",
    "    --packages io.delta:delta-core_2.12:2.4.0 \\\n",
    "    --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension \\\n",
    "    --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog \\\n",
    "    -i /opt/bitnami/spark/work/scripts/generate_training_labels.scala\n",
    "\n",
    "sudo chown -R dinindu:dinindu $kkbox_churn_dir/silver/train\n",
    "sudo chmod -R 777 $kkbox_churn_dir/silver/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training labels\n",
    "_ = spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS train\n",
    "USING DELTA\n",
    "LOCATION '/home/dinindu/databricks/kkbox_churn/silver/train/'\n",
    "''')\n",
    "\n",
    "_ = spark.sql('SELECT * FROM train').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete testing labels if exists before create\n",
    "_ = spark.sql('DROP TABLE IF EXISTS test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing labels\n",
    "%%sh -e\n",
    "\n",
    "kkbox_churn_dir=\"/home/dinindu/databricks/kkbox_churn\"\n",
    "sudo chmod 777 $kkbox_churn_dir\n",
    "sudo rm -rf $kkbox_churn_dir/silver/test\n",
    "\n",
    "docker run --rm --network host  \\\n",
    "    -v \"$kkbox_churn_dir:/opt/spark/work/kkbox_churn\" \\\n",
    "    -v \"$PWD:/opt/bitnami/spark/work\" \\\n",
    "    bitnami/spark:3.4.1 spark-shell --master local[*] \\\n",
    "    --executor-memory 48G \\\n",
    "    --driver-memory 16G \\\n",
    "    --packages io.delta:delta-core_2.12:2.4.0 \\\n",
    "    --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension \\\n",
    "    --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog \\\n",
    "    -i /opt/bitnami/spark/work/scripts/generate_testing_labels.scala\n",
    "\n",
    "sudo chown -R dinindu:dinindu $kkbox_churn_dir/silver/test\n",
    "sudo chmod -R 777 $kkbox_churn_dir/silver/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the testing labels\n",
    "_ = spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS test\n",
    "USING DELTA\n",
    "LOCATION '/home/dinindu/databricks/kkbox_churn/silver/test/'\n",
    "              ''')\n",
    "\n",
    "_ = spark.sql('SELECT * FROM test').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Cleanse & Enhance Transaction Logs\n",
    "\n",
    "In the churn script provided by KKBox (and used in the last step), time between transaction events is used in order to determine churn status. In situations where multiple transactions are recorded on a given date, complex logic is used to determine which transaction represents the final state of the account on that date. This logic states that when we have multiple transactions for a given subscriber on a given date, we should:\n",
    "\n",
    "1. Concatenate the plan_list_price, payment_plan_days, and payment_method_id values and consider the \"bigger\" of these values as preceding the others\n",
    "2. If the concatenated value (defined in the last step) is the same across records for this date, cancellations, i.e. records where is_cancel=1, should follow other transactions\n",
    "3. If there are multiple cancellations in this sequence, the record with the earliest expiration date is the last record for this transaction date\n",
    "4. If there are no cancellations but multiple non-cancellations in this sequence, the non-cancellation record with the latest expiration date is the last record on the transaction date\n",
    "Rewriting this logic in SQL allows us to generate a cleansed version of the transaction log with the final record for each date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ipython-sql\n",
    "%reload_ext sql\n",
    "%sql sqlite:////home/dinindu/Projects/dini-ai-ml/kaggle/churn/spark-warehouse/kkbox_churn.db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nextraneous input 'CREATE' expecting {<EOF>, ';'}(line 4, pos 4)\n\n== SQL ==\n\n    DROP TABLE IF EXISTS transactions_clean;\n\n    CREATE TABLE transactions_clean\n----^^^\n    USING DELTA\n    AS\n    WITH \n        transaction_sequenced (\n        SELECT\n            msno,\n            transaction_date,\n            plan_list_price,\n            payment_plan_days,\n            payment_method_id,\n            is_cancel,\n            membership_expire_date,\n            RANK() OVER (PARTITION BY msno, transaction_date ORDER BY plan_sort DESC, is_cancel) as sort_id  -- calc rank on price, days & method sort followed by cancel sort\n        FROM (\n            SELECT\n            msno,\n            transaction_date,\n            plan_list_price,\n            payment_plan_days,\n            payment_method_id,\n            CONCAT(CAST(plan_list_price as string), CAST(payment_plan_days as string), CAST(payment_method_id as string)) as plan_sort,\n            is_cancel,\n            membership_expire_date\n            FROM transactions\n            )\n        )\n    SELECT\n        p.msno,\n        p.transaction_date,\n        p.plan_list_price,\n        p.actual_amount_paid,\n        p.plan_list_price - p.actual_amount_paid as discount,\n        p.payment_plan_days,\n        p.payment_method_id,\n        p.is_cancel,\n        p.is_auto_renew,\n        p.membership_expire_date\n    FROM transactions p\n    INNER JOIN (\n        SELECT\n        x.msno,\n        x.transaction_date,\n        x.plan_list_price,\n        x.payment_plan_days,\n        x.payment_method_id,\n        x.is_cancel,\n        CASE   -- if is_cancel is 0 in last record then go with max membership date identified, otherwise go with lowest membership date\n            WHEN x.is_cancel=0 THEN MAX(x.membership_expire_date)\n            ELSE MIN(x.membership_expire_date)\n            END as membership_expire_date\n        FROM (\n        SELECT\n            a.msno,\n            a.transaction_date,\n            a.plan_list_price,\n            a.payment_plan_days,\n            a.payment_method_id,\n            a.is_cancel,\n            a.membership_expire_date\n        FROM transaction_sequenced a\n        INNER JOIN (\n            SELECT msno, transaction_date, MAX(sort_id) as max_sort_id -- find last entries on a given date\n            FROM transaction_sequenced \n            GROUP BY msno, transaction_date\n            ) b\n            ON a.msno=b.msno AND a.transaction_date=b.transaction_date AND a.sort_id=b.max_sort_id\n            ) x\n        GROUP BY \n        x.msno, \n        x.transaction_date, \n        x.plan_list_price,\n        x.payment_plan_days,\n        x.payment_method_id,\n        x.is_cancel\n    ) q\n    ON \n        p.msno=q.msno AND \n        p.transaction_date=q.transaction_date AND \n        p.plan_list_price=q.plan_list_price AND \n        p.payment_plan_days=q.payment_plan_days AND \n        p.payment_method_id=q.payment_method_id AND \n        p.is_cancel=q.is_cancel AND \n        p.membership_expire_date=q.membership_expire_date;\n        \n    \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m    DROP TABLE IF EXISTS transactions_clean;\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    CREATE TABLE transactions_clean\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    USING DELTA\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    AS\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    WITH \u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m        transaction_sequenced (\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m        SELECT\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m            msno,\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m            transaction_date,\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m            plan_list_price,\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m            payment_plan_days,\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m            payment_method_id,\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m            is_cancel,\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m            membership_expire_date,\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m            RANK() OVER (PARTITION BY msno, transaction_date ORDER BY plan_sort DESC, is_cancel) as sort_id  -- calc rank on price, days & method sort followed by cancel sort\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m        FROM (\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m            SELECT\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43m            msno,\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m            transaction_date,\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43m            plan_list_price,\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m            payment_plan_days,\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;43m            payment_method_id,\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m            CONCAT(CAST(plan_list_price as string), CAST(payment_plan_days as string), CAST(payment_method_id as string)) as plan_sort,\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43m            is_cancel,\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43m            membership_expire_date\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43m            FROM transactions\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43m            )\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43m        )\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43m    SELECT\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43m        p.msno,\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;43m        p.transaction_date,\u001b[39;49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43m        p.plan_list_price,\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43m        p.actual_amount_paid,\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43m        p.plan_list_price - p.actual_amount_paid as discount,\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43m        p.payment_plan_days,\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;43m        p.payment_method_id,\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;43m        p.is_cancel,\u001b[39;49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;43m        p.is_auto_renew,\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;43m        p.membership_expire_date\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;43m    FROM transactions p\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;43m    INNER JOIN (\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;43m        SELECT\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;43m        x.msno,\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43m        x.transaction_date,\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;43m        x.plan_list_price,\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;43m        x.payment_plan_days,\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;43m        x.payment_method_id,\u001b[39;49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;43m        x.is_cancel,\u001b[39;49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;43m        CASE   -- if is_cancel is 0 in last record then go with max membership date identified, otherwise go with lowest membership date\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;43m            WHEN x.is_cancel=0 THEN MAX(x.membership_expire_date)\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;43m            ELSE MIN(x.membership_expire_date)\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;43m            END as membership_expire_date\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;43m        FROM (\u001b[39;49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;43m        SELECT\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;43m            a.msno,\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;43m            a.transaction_date,\u001b[39;49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;43m            a.plan_list_price,\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;43m            a.payment_plan_days,\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;43m            a.payment_method_id,\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;43m            a.is_cancel,\u001b[39;49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;43m            a.membership_expire_date\u001b[39;49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;43m        FROM transaction_sequenced a\u001b[39;49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;43m        INNER JOIN (\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;43m            SELECT msno, transaction_date, MAX(sort_id) as max_sort_id -- find last entries on a given date\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;43m            FROM transaction_sequenced \u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;43m            GROUP BY msno, transaction_date\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;43m            ) b\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;43m            ON a.msno=b.msno AND a.transaction_date=b.transaction_date AND a.sort_id=b.max_sort_id\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;43m            ) x\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;43m        GROUP BY \u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;43m        x.msno, \u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;43m        x.transaction_date, \u001b[39;49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;43m        x.plan_list_price,\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;43m        x.payment_plan_days,\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;43m        x.payment_method_id,\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;43m        x.is_cancel\u001b[39;49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;43m    ) q\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;43m    ON \u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;43m        p.msno=q.msno AND \u001b[39;49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;43m        p.transaction_date=q.transaction_date AND \u001b[39;49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;43m        p.plan_list_price=q.plan_list_price AND \u001b[39;49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;43m        p.payment_plan_days=q.payment_plan_days AND \u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;43m        p.payment_method_id=q.payment_method_id AND \u001b[39;49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;43m        p.is_cancel=q.is_cancel AND \u001b[39;49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;43m        p.membership_expire_date=q.membership_expire_date;\u001b[39;49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/churn/lib/python3.11/site-packages/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m~/miniconda3/envs/churn/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/miniconda3/envs/churn/lib/python3.11/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \nextraneous input 'CREATE' expecting {<EOF>, ';'}(line 4, pos 4)\n\n== SQL ==\n\n    DROP TABLE IF EXISTS transactions_clean;\n\n    CREATE TABLE transactions_clean\n----^^^\n    USING DELTA\n    AS\n    WITH \n        transaction_sequenced (\n        SELECT\n            msno,\n            transaction_date,\n            plan_list_price,\n            payment_plan_days,\n            payment_method_id,\n            is_cancel,\n            membership_expire_date,\n            RANK() OVER (PARTITION BY msno, transaction_date ORDER BY plan_sort DESC, is_cancel) as sort_id  -- calc rank on price, days & method sort followed by cancel sort\n        FROM (\n            SELECT\n            msno,\n            transaction_date,\n            plan_list_price,\n            payment_plan_days,\n            payment_method_id,\n            CONCAT(CAST(plan_list_price as string), CAST(payment_plan_days as string), CAST(payment_method_id as string)) as plan_sort,\n            is_cancel,\n            membership_expire_date\n            FROM transactions\n            )\n        )\n    SELECT\n        p.msno,\n        p.transaction_date,\n        p.plan_list_price,\n        p.actual_amount_paid,\n        p.plan_list_price - p.actual_amount_paid as discount,\n        p.payment_plan_days,\n        p.payment_method_id,\n        p.is_cancel,\n        p.is_auto_renew,\n        p.membership_expire_date\n    FROM transactions p\n    INNER JOIN (\n        SELECT\n        x.msno,\n        x.transaction_date,\n        x.plan_list_price,\n        x.payment_plan_days,\n        x.payment_method_id,\n        x.is_cancel,\n        CASE   -- if is_cancel is 0 in last record then go with max membership date identified, otherwise go with lowest membership date\n            WHEN x.is_cancel=0 THEN MAX(x.membership_expire_date)\n            ELSE MIN(x.membership_expire_date)\n            END as membership_expire_date\n        FROM (\n        SELECT\n            a.msno,\n            a.transaction_date,\n            a.plan_list_price,\n            a.payment_plan_days,\n            a.payment_method_id,\n            a.is_cancel,\n            a.membership_expire_date\n        FROM transaction_sequenced a\n        INNER JOIN (\n            SELECT msno, transaction_date, MAX(sort_id) as max_sort_id -- find last entries on a given date\n            FROM transaction_sequenced \n            GROUP BY msno, transaction_date\n            ) b\n            ON a.msno=b.msno AND a.transaction_date=b.transaction_date AND a.sort_id=b.max_sort_id\n            ) x\n        GROUP BY \n        x.msno, \n        x.transaction_date, \n        x.plan_list_price,\n        x.payment_plan_days,\n        x.payment_method_id,\n        x.is_cancel\n    ) q\n    ON \n        p.msno=q.msno AND \n        p.transaction_date=q.transaction_date AND \n        p.plan_list_price=q.plan_list_price AND \n        p.payment_plan_days=q.payment_plan_days AND \n        p.payment_method_id=q.payment_method_id AND \n        p.is_cancel=q.is_cancel AND \n        p.membership_expire_date=q.membership_expire_date;\n        \n    \n"
     ]
    }
   ],
   "source": [
    "_ = spark.sql('''\n",
    "    DROP TABLE IF EXISTS transactions_clean;\n",
    "\n",
    "    CREATE TABLE transactions_clean\n",
    "    USING DELTA\n",
    "    AS\n",
    "    WITH \n",
    "        transaction_sequenced (\n",
    "        SELECT\n",
    "            msno,\n",
    "            transaction_date,\n",
    "            plan_list_price,\n",
    "            payment_plan_days,\n",
    "            payment_method_id,\n",
    "            is_cancel,\n",
    "            membership_expire_date,\n",
    "            RANK() OVER (PARTITION BY msno, transaction_date ORDER BY plan_sort DESC, is_cancel) as sort_id  -- calc rank on price, days & method sort followed by cancel sort\n",
    "        FROM (\n",
    "            SELECT\n",
    "            msno,\n",
    "            transaction_date,\n",
    "            plan_list_price,\n",
    "            payment_plan_days,\n",
    "            payment_method_id,\n",
    "            CONCAT(CAST(plan_list_price as string), CAST(payment_plan_days as string), CAST(payment_method_id as string)) as plan_sort,\n",
    "            is_cancel,\n",
    "            membership_expire_date\n",
    "            FROM transactions\n",
    "            )\n",
    "        )\n",
    "    SELECT\n",
    "        p.msno,\n",
    "        p.transaction_date,\n",
    "        p.plan_list_price,\n",
    "        p.actual_amount_paid,\n",
    "        p.plan_list_price - p.actual_amount_paid as discount,\n",
    "        p.payment_plan_days,\n",
    "        p.payment_method_id,\n",
    "        p.is_cancel,\n",
    "        p.is_auto_renew,\n",
    "        p.membership_expire_date\n",
    "    FROM transactions p\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "        x.msno,\n",
    "        x.transaction_date,\n",
    "        x.plan_list_price,\n",
    "        x.payment_plan_days,\n",
    "        x.payment_method_id,\n",
    "        x.is_cancel,\n",
    "        CASE   -- if is_cancel is 0 in last record then go with max membership date identified, otherwise go with lowest membership date\n",
    "            WHEN x.is_cancel=0 THEN MAX(x.membership_expire_date)\n",
    "            ELSE MIN(x.membership_expire_date)\n",
    "            END as membership_expire_date\n",
    "        FROM (\n",
    "        SELECT\n",
    "            a.msno,\n",
    "            a.transaction_date,\n",
    "            a.plan_list_price,\n",
    "            a.payment_plan_days,\n",
    "            a.payment_method_id,\n",
    "            a.is_cancel,\n",
    "            a.membership_expire_date\n",
    "        FROM transaction_sequenced a\n",
    "        INNER JOIN (\n",
    "            SELECT msno, transaction_date, MAX(sort_id) as max_sort_id -- find last entries on a given date\n",
    "            FROM transaction_sequenced \n",
    "            GROUP BY msno, transaction_date\n",
    "            ) b\n",
    "            ON a.msno=b.msno AND a.transaction_date=b.transaction_date AND a.sort_id=b.max_sort_id\n",
    "            ) x\n",
    "        GROUP BY \n",
    "        x.msno, \n",
    "        x.transaction_date, \n",
    "        x.plan_list_price,\n",
    "        x.payment_plan_days,\n",
    "        x.payment_method_id,\n",
    "        x.is_cancel\n",
    "    ) q\n",
    "    ON \n",
    "        p.msno=q.msno AND \n",
    "        p.transaction_date=q.transaction_date AND \n",
    "        p.plan_list_price=q.plan_list_price AND \n",
    "        p.payment_plan_days=q.payment_plan_days AND \n",
    "        p.payment_method_id=q.payment_method_id AND \n",
    "        p.is_cancel=q.is_cancel AND \n",
    "        p.membership_expire_date=q.membership_expire_date;\n",
    "        \n",
    "    ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
